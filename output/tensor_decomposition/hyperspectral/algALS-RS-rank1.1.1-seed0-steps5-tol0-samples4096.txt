###################################
2022-05-23 14:34:00.322476
Namespace(data='hyperspectral', algorithm='ALS-RS', rank='1,1,1', seed=0, alpha=1.0, max_num_samples=4096, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
Loading hyperspectral tensor...
Finished.
AlgorithmConfig(input_shape=(1024, 1344, 33), rank=(1, 1, 1), l2_regularization_strength=0.0, algorithm='ALS-RS', random_seed=0, epsilon=0.1, delta=0.01, downsampling_ratio=1.0, max_num_samples=4096, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
step: 0
loss: 22265.42658570579 rmse: 0.02214159626631701 rre: 0.7002626793762806 time: 0.5435789569999998
loss: 14386.673551575152 rmse: 0.017798098745460147 rre: 0.5628927637100607 time: 0.2106620079999999
loss: 3343.23831870397 rmse: 0.008579798439154842 rre: 0.2713495707918252 time: 0.5237762640000003
loss: 3343.246069215557 rmse: 0.008579808384271272 rre: 0.27134988532171705 time: 0.5060022059999998
Warning: The loss function increased!
rre_diff: 4.018670813756486

step: 1
loss: 3337.1583000046617 rmse: 0.008571993271148156 rre: 0.27110272012236114 time: 0.5428490719999992
loss: 3336.5998159796786 rmse: 0.008571275966006488 rre: 0.27108003422318777 time: 0.20966599299999977
loss: 3336.5835460898875 rmse: 0.008571255068402187 rre: 0.2710793733037037 time: 0.5224836110000002
loss: 3337.2467001257182 rmse: 0.008572106804903012 rre: 0.271106310805274 time: 0.5051651620000008
Warning: The loss function increased!
rre_diff: 0.00024357451644307915

step: 2
loss: 3336.581271339866 rmse: 0.008571252146631203 rre: 0.2710792808981177 time: 0.5435721480000009
loss: 3336.5812363107834 rmse: 0.008571252101638577 rre: 0.2710792794751555 time: 0.21033300600000082
loss: 3336.581234576023 rmse: 0.00857125209941039 rre: 0.27107927940468546 time: 0.5222864550000015
loss: 3337.093006727633 rmse: 0.008571909412934262 rre: 0.27110006797493497 time: 0.506080377
Warning: The loss function increased!
rre_diff: 6.242830339009409e-06

step: 3
loss: 3336.5812341535498 rmse: 0.008571252098867749 rre: 0.27107927938752363 time: 0.5425896090000002
loss: 3336.581234141431 rmse: 0.008571252098852183 rre: 0.27107927938703136 time: 0.2077462900000029
loss: 3336.5812341417704 rmse: 0.008571252098852618 rre: 0.2710792793870451 time: 0.5218331539999994
Warning: The loss function increased!
loss: 3337.0201653858176 rmse: 0.008571815859534702 rre: 0.27109710920206903 time: 0.5087185350000034
Warning: The loss function increased!
rre_diff: 2.9587728659352663e-06

step: 4
loss: 3336.5812341419314 rmse: 0.008571252098852825 rre: 0.2710792793870517 time: 0.5426089480000016
loss: 3336.5812341414207 rmse: 0.00857125209885217 rre: 0.2710792793870309 time: 0.21124676899999884
loss: 3336.581234143313 rmse: 0.0085712520988546 rre: 0.2710792793871078 time: 0.523079936000002
Warning: The loss function increased!
loss: 3336.8854968802575 rmse: 0.008571642896049165 rre: 0.27109163896079286 time: 0.5045395940000006
Warning: The loss function increased!
rre_diff: 5.470241276173127e-06

