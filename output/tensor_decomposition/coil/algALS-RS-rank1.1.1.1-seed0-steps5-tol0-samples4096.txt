###################################
2022-05-17 16:22:03.494163
Namespace(data='coil', algorithm='ALS-RS', rank='1,1,1,1', seed=0, alpha=1.0, max_num_samples=4096, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
Loading COIL-100 tensor...
Finished.
AlgorithmConfig(input_shape=(7200, 128, 128, 3), rank=(1, 1, 1, 1), l2_regularization_strength=0.0, algorithm='ALS-RS', random_seed=0, epsilon=0.1, delta=0.01, downsampling_ratio=1.0, max_num_samples=4096, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
step: 0
loss: 30299349.119248237 rmse: 0.292603693852046 rre: 0.8449430330330274 time: 0.610346109
loss: 25405008.5243273 rmse: 0.26793091501898764 rre: 0.773696179289962 time: 1.2075866929999997
loss: 17668718.956930164 rmse: 0.22344245077639466 rre: 0.6452281568352447 time: 4.972983739
loss: 11993256.084261313 rmse: 0.1840906402967521 rre: 0.5315930975361545 time: 1.3334114250000013
loss: 11993521.176129935 rmse: 0.1840926748010529 rre: 0.5315989725140539 time: 0.018829228999997838
Warning: The loss function increased!
rre_diff: 0.427392971665816

step: 1
loss: 11853872.780036805 rmse: 0.1830177811257754 rre: 0.5284950338377492 time: 0.5999569630000039
loss: 11849718.191765642 rmse: 0.18298570594762864 rre: 0.5284024112944324 time: 1.2023356289999967
loss: 11848472.19809976 rmse: 0.18297608525367257 rre: 0.5283746299010259 time: 5.020649294000002
loss: 11846184.99604623 rmse: 0.18295842375818097 rre: 0.5283236293228305 time: 1.3621628470000005
loss: 11847582.911161246 rmse: 0.18296921849088346 rre: 0.5283548009532032 time: 0.01854334899999799
Warning: The loss function increased!
rre_diff: 0.0032441715608506616

step: 2
loss: 11846091.14710133 rmse: 0.18295769903165324 rre: 0.5283215365514701 time: 0.6034562500000007
loss: 11846088.485099752 rmse: 0.18295767847492675 rre: 0.528321477190419 time: 1.2416170629999996
loss: 11846087.33210593 rmse: 0.18295766957118278 rre: 0.5283214514793408 time: 5.001833452999989
loss: 11846084.953165896 rmse: 0.1829576512003345 rre: 0.5283213984303855 time: 1.3626502589999916
loss: 11846085.67656489 rmse: 0.18295765678662648 rre: 0.5283214145617556 time: 0.01868447900000092
Warning: The loss function increased!
rre_diff: 3.338639144756517e-05

step: 3
loss: 11846084.835891288 rmse: 0.18295765029470673 rre: 0.5283213958152311 time: 0.6041797949999932
loss: 11846084.832378412 rmse: 0.1829576502675793 rre: 0.528321395736896 time: 1.244679829000006
loss: 11846084.831032656 rmse: 0.182957650257187 rre: 0.5283213957068864 time: 4.970472497000003
loss: 11846084.827621829 rmse: 0.18295765023084762 rre: 0.5283213956308269 time: 1.3365597079999958
loss: 11846312.585543279 rmse: 0.18295940903362706 rre: 0.5283264744735968 time: 0.018554898999994407
Warning: The loss function increased!
rre_diff: -5.059911841187592e-06

step: 4
loss: 11846084.827412233 rmse: 0.18295765022922908 rre: 0.5283213956261531 time: 0.5953189850000058
loss: 11846084.827421345 rmse: 0.1829576502292994 rre: 0.5283213956263563 time: 1.2079174290000054
Warning: The loss function increased!
loss: 11846084.82740797 rmse: 0.18295765022919613 rre: 0.528321395626058 time: 5.010950956000002
loss: 11846084.827409502 rmse: 0.18295765022920799 rre: 0.5283213956260921 time: 1.349984457000005
Warning: The loss function increased!
loss: 11846190.21274673 rmse: 0.18295846404284627 rre: 0.5283237456516671 time: 0.018606197000025304
Warning: The loss function increased!
rre_diff: 2.7288219297538774e-06

