###################################
2022-05-23 21:21:05.480162
Namespace(data='coil', algorithm='ALS-RS', rank='1,1,1,1', seed=0, alpha=1.0, max_num_samples=1024, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
Loading COIL-100 tensor...
Finished.
AlgorithmConfig(input_shape=(7200, 128, 128, 3), rank=(1, 1, 1, 1), l2_regularization_strength=0.0, algorithm='ALS-RS', random_seed=0, epsilon=0.1, delta=0.01, downsampling_ratio=1.0, max_num_samples=1024, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
step: 0
loss: 30299349.119248237 rmse: 0.292603693852046 rre: 0.8449430330330274 time: 0.5898231549999995
loss: 25405008.5243273 rmse: 0.26793091501898764 rre: 0.773696179289962 time: 1.1966021420000015
loss: 17668718.956930164 rmse: 0.22344245077639466 rre: 0.6452281568352447 time: 4.980059816000001
loss: 11993256.084261313 rmse: 0.1840906402967521 rre: 0.5315930975361545 time: 1.3175744219999999
loss: 11995672.00695995 rmse: 0.18410918098153664 rre: 0.5316466369232692 time: 0.017273969999997973
Warning: The loss function increased!
rre_diff: 0.4273453072566007

step: 1
loss: 11853872.780036805 rmse: 0.1830177811257754 rre: 0.5284950338377492 time: 0.5944839229999985
loss: 11849718.191765638 rmse: 0.18298570594762859 rre: 0.5284024112944324 time: 1.1993577630000019
loss: 11848472.198099758 rmse: 0.18297608525367257 rre: 0.5283746299010259 time: 4.982227865999995
loss: 11846184.996046236 rmse: 0.182958423758181 rre: 0.5283236293228306 time: 1.3161065519999937
loss: 11851284.92574143 rmse: 0.18299780245668731 rre: 0.5284373420258891 time: 0.017174017999998625
Warning: The loss function increased!
rre_diff: 0.0032092948973800883

step: 2
loss: 11846091.147101317 rmse: 0.18295769903165313 rre: 0.5283215365514697 time: 0.5915055689999988
loss: 11846088.485099787 rmse: 0.18295767847492705 rre: 0.5283214771904198 time: 1.2038907119999962
loss: 11846087.332105944 rmse: 0.1829576695711829 rre: 0.5283214514793412 time: 4.956734576000002
loss: 11846084.95316588 rmse: 0.1829576512003344 rre: 0.5283213984303852 time: 1.3170974260000037
loss: 11850819.897651963 rmse: 0.182994212130668 rre: 0.5284269743476264 time: 0.017183323000011796
Warning: The loss function increased!
rre_diff: 1.036767826267937e-05

step: 3
loss: 11846084.8358913 rmse: 0.18295765029470684 rre: 0.5283213958152313 time: 0.5924883099999931
loss: 11846084.832378415 rmse: 0.18295765026757935 rre: 0.5283213957368961 time: 1.2000600619999915
loss: 11846084.83103267 rmse: 0.1829576502571871 rre: 0.5283213957068866 time: 4.957816882000003
loss: 11846084.82762183 rmse: 0.18295765023084762 rre: 0.528321395630827 time: 1.3161383919999992
loss: 11849343.184605194 rmse: 0.18298281045712841 rre: 0.5283940500721487 time: 0.017125868000007927
Warning: The loss function increased!
rre_diff: 3.292427547774146e-05

step: 4
loss: 11846084.827412233 rmse: 0.18295765022922908 rre: 0.5283213956261531 time: 0.5918732749999975
loss: 11846084.827421347 rmse: 0.18295765022929944 rre: 0.5283213956263564 time: 1.2353383640000004
Warning: The loss function increased!
loss: 11846084.82740797 rmse: 0.18295765022919613 rre: 0.528321395626058 time: 4.960677363000002
loss: 11846084.827409515 rmse: 0.18295765022920807 rre: 0.5283213956260925 time: 1.3268659780000007
Warning: The loss function increased!
loss: 11849827.828645218 rmse: 0.18298655246292453 rre: 0.5284048557516169 time: 0.018389198999997802
Warning: The loss function increased!
rre_diff: -1.0805679468206542e-05

