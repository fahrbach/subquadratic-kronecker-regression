###################################
2022-05-17 16:28:37.614845
Namespace(data='coil', algorithm='ALS-DJSSW19', rank='1,1,1,1', seed=0, alpha=1.0, max_num_samples=16384, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
Loading COIL-100 tensor...
Finished.
AlgorithmConfig(input_shape=(7200, 128, 128, 3), rank=(1, 1, 1, 1), l2_regularization_strength=0.0, algorithm='ALS-DJSSW19', random_seed=0, epsilon=0.1, delta=0.01, downsampling_ratio=1.0, max_num_samples=16384, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
step: 0
loss: 30299349.119248237 rmse: 0.292603693852046 rre: 0.8449430330330274 time: 0.6096644410000014
loss: 25405008.5243273 rmse: 0.26793091501898764 rre: 0.773696179289962 time: 1.2468289939999995
loss: 17668718.956930164 rmse: 0.22344245077639466 rre: 0.6452281568352447 time: 5.001876377999999
loss: 11993256.084261313 rmse: 0.1840906402967521 rre: 0.5315930975361545 time: 1.3659680129999998
loss: 11993273.391123911 rmse: 0.18409077312266048 rre: 0.5315934810936018 time: 0.019865773999999448
Warning: The loss function increased!
rre_diff: 0.42739846308626805

step: 1
loss: 11853872.780036805 rmse: 0.1830177811257754 rre: 0.5284950338377492 time: 0.5989434250000016
loss: 11849718.191765634 rmse: 0.18298570594762859 rre: 0.5284024112944323 time: 1.2023798809999988
loss: 11848472.198099747 rmse: 0.18297608525367245 rre: 0.5283746299010257 time: 4.987271057000001
loss: 11846184.996046241 rmse: 0.18295842375818105 rre: 0.5283236293228307 time: 1.3271290220000012
loss: 11849278.917668499 rmse: 0.18298231423719208 rre: 0.5283926171525141 time: 0.019803910999996788
Warning: The loss function increased!
rre_diff: 0.0032008639410877615

step: 2
loss: 11846091.147101335 rmse: 0.1829576990316533 rre: 0.5283215365514702 time: 0.590771973999999
loss: 11846088.485099742 rmse: 0.1829576784749267 rre: 0.5283214771904188 time: 1.2029743070000052
loss: 11846087.332105944 rmse: 0.1829576695711829 rre: 0.5283214514793412 time: 4.964479905999994
loss: 11846084.953165887 rmse: 0.18295765120033444 rre: 0.5283213984303853 time: 1.3317862480000002
loss: 11846322.15568914 rmse: 0.18295948293628092 rre: 0.5283266878801047 time: 0.019842048999990425
Warning: The loss function increased!
rre_diff: 6.592927240933744e-05

step: 3
loss: 11846084.835891291 rmse: 0.18295765029470676 rre: 0.5283213958152311 time: 0.58979575299999
loss: 11846084.83237841 rmse: 0.1829576502675793 rre: 0.5283213957368958 time: 1.2024145600000082
loss: 11846084.831032665 rmse: 0.18295765025718708 rre: 0.5283213957068866 time: 4.978855334000002
loss: 11846084.827621847 rmse: 0.18295765023084776 rre: 0.5283213956308274 time: 1.328774593999995
loss: 11846855.062277116 rmse: 0.18296359810451712 rre: 0.528338571129715 time: 0.01989249100000734
Warning: The loss function increased!
rre_diff: -1.1883249610322721e-05

step: 4
loss: 11846084.827412233 rmse: 0.18295765022922908 rre: 0.5283213956261531 time: 0.5908849140000001
loss: 11846084.827421347 rmse: 0.18295765022929944 rre: 0.5283213956263564 time: 1.2038265590000066
Warning: The loss function increased!
loss: 11846084.827407965 rmse: 0.1829576502291961 rre: 0.528321395626058 time: 4.972946469000007
loss: 11846084.827409508 rmse: 0.182957650229208 rre: 0.5283213956260924 time: 1.382428277999992
Warning: The loss function increased!
loss: 11847729.290364128 rmse: 0.18297034879762322 rre: 0.5283580649065469 time: 0.019862099000008016
Warning: The loss function increased!
rre_diff: -1.9493776831858156e-05

