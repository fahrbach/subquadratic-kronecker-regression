###################################
2022-05-17 16:26:26.682088
Namespace(data='coil', algorithm='ALS-RS', rank='1,1,1,1', seed=0, alpha=1.0, max_num_samples=16384, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
Loading COIL-100 tensor...
Finished.
AlgorithmConfig(input_shape=(7200, 128, 128, 3), rank=(1, 1, 1, 1), l2_regularization_strength=0.0, algorithm='ALS-RS', random_seed=0, epsilon=0.1, delta=0.01, downsampling_ratio=1.0, max_num_samples=16384, max_num_steps=5, rre_gap_tol=0.0, verbose=False)
step: 0
loss: 30299349.119248237 rmse: 0.292603693852046 rre: 0.8449430330330274 time: 0.6099104420000003
loss: 25405008.5243273 rmse: 0.26793091501898764 rre: 0.773696179289962 time: 1.2516305840000008
loss: 17668718.956930164 rmse: 0.22344245077639466 rre: 0.6452281568352447 time: 5.008758902
loss: 11993256.084261313 rmse: 0.1840906402967521 rre: 0.5315930975361545 time: 1.364864279999999
loss: 11996036.912919201 rmse: 0.18411198124259504 rre: 0.5316547231543103 time: 0.021997480999999652
Warning: The loss function increased!
rre_diff: 0.4273372210255596

step: 1
loss: 11853872.780036805 rmse: 0.1830177811257754 rre: 0.5284950338377492 time: 0.5945346179999973
loss: 11849718.191765632 rmse: 0.18298570594762856 rre: 0.5284024112944322 time: 1.2036227830000001
loss: 11848472.198099751 rmse: 0.1829760852536725 rre: 0.5283746299010257 time: 4.961449654999996
loss: 11846184.996046232 rmse: 0.18295842375818097 rre: 0.5283236293228305 time: 1.330177693000003
loss: 11847960.514183687 rmse: 0.18297213424086978 rre: 0.5283632206782058 time: 0.021878904000004695
Warning: The loss function increased!
rre_diff: 0.0032915024761044354

step: 2
loss: 11846091.147101324 rmse: 0.18295769903165318 rre: 0.52832153655147 time: 0.5934609430000037
loss: 11846088.48509976 rmse: 0.18295767847492683 rre: 0.5283214771904192 time: 1.2033451609999943
loss: 11846087.332105944 rmse: 0.1829576695711829 rre: 0.5283214514793412 time: 4.962602298000007
loss: 11846084.953165887 rmse: 0.18295765120033444 rre: 0.5283213984303853 time: 1.3347046040000095
loss: 11849349.546339162 rmse: 0.1829828595774799 rre: 0.5283941919155349 time: 0.021812111999992112
Warning: The loss function increased!
rre_diff: -3.097123732909157e-05

step: 3
loss: 11846084.835891295 rmse: 0.1829576502947068 rre: 0.5283213958152312 time: 0.6045087319999993
loss: 11846084.83237841 rmse: 0.1829576502675793 rre: 0.5283213957368958 time: 1.2334024299999982
loss: 11846084.831032647 rmse: 0.1829576502571869 rre: 0.5283213957068862 time: 4.985653526999997
loss: 11846084.82762184 rmse: 0.1829576502308477 rre: 0.5283213956308273 time: 1.3606567439999964
loss: 11846987.201029755 rmse: 0.18296461848140572 rre: 0.5283415176418788 time: 0.021738640999998893
Warning: The loss function increased!
rre_diff: 5.26742736561836e-05

step: 4
loss: 11846084.827412242 rmse: 0.18295765022922914 rre: 0.5283213956261533 time: 0.5936326669999943
loss: 11846084.827421337 rmse: 0.18295765022929936 rre: 0.5283213956263562 time: 1.2034894399999985
Warning: The loss function increased!
loss: 11846084.827407965 rmse: 0.1829576502291961 rre: 0.528321395626058 time: 4.965935986999995
loss: 11846084.82740948 rmse: 0.18295765022920782 rre: 0.5283213956260917 time: 1.3320151069999895
Warning: The loss function increased!
loss: 11846163.778469173 rmse: 0.18295825991065562 rre: 0.5283231561851773 time: 0.021794771000003266
Warning: The loss function increased!
rre_diff: 1.8361456701421197e-05

